{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d813fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f9ec4",
   "metadata": {},
   "source": [
    "Data Processing Prepare Training Data Set for DNN solution. \n",
    "For the data of 33 person, we chose 30 for training and 3 for validation. \n",
    "First Let's parse csvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90a380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_data(df):\n",
    "    df['time'] = pd.to_datetime(df['time'])   # convert 'time' to datetime object\n",
    "    df['time'] = df['time'].dt.floor(\"S\")\n",
    "    df['Second'] = df['time'].dt.second\n",
    "    df['Minute'] = df['time'].dt.minute\n",
    "    df_second = df.groupby(['Minute','Second']).mean()\n",
    "    return df_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710f9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ['w','t']\n",
    "label = ['downstairs','jogging','upstairs','walk_fast','walk_mod','walk_slow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97fef11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for loc_i in loc:\n",
    "    for label_i in label:\n",
    "        for num in range(26, 64):\n",
    "            path = './%s/%s/0%g.csv'%(loc_i,label_i,num)\n",
    "            new_path = './%s/%s/0%g_second.csv'%(loc_i,label_i,num)\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                new_df = get_second_data(df)\n",
    "                new_df.to_csv(new_path)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6a87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_t_w(id, label,label_id):\n",
    "    w_path = './w/%s/0%g_second.csv'%(label, id)\n",
    "    t_path = './t/%s/0%g_second.csv'%(label, id)\n",
    "    df_w = pd.read_csv(w_path)\n",
    "    df_t = pd.read_csv(t_path)\n",
    "    df_w = df_w.rename(columns={'x':'w_x','y':'w_y','z':'w_z'})\n",
    "    df_t = df_t.rename(columns={'x':'t_x','y':'t_y','z':'t_z'})\n",
    "    df_t_w = pd.merge(df_w,df_t)\n",
    "    df_t_w['label_id'] = label_id\n",
    "    return df_t_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b4af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_i in label:\n",
    "    for num in range(26, 64):\n",
    "        path = './%s/%s/0%g.csv'%(loc_i,label_i,num)\n",
    "        new_path = './%s/%s/0%g_second.csv'%(loc_i,label_i,num)\n",
    "        try:\n",
    "            df = pd.read_csv(path)\n",
    "            new_df = get_second_data(df)\n",
    "            new_df.to_csv(new_path)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b811fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_i in label:\n",
    "    os.makedirs('./combined_data/'+ label_i, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b520386",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Minute','Second','w_x','w_y','w_z','t_x','t_y','t_z']\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12a434dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(window_length, stride, new_df):\n",
    "    data = []\n",
    "    label_id = new_df.iloc[0]['label_id']\n",
    "    for i in range(0,len(new_df)-window_length,stride):\n",
    "        start = i\n",
    "        end = i + window_length\n",
    "        np_data = np.array([])\n",
    "        np_data = np.append(new_df.iloc[0:10][['w_x','w_y','w_z','t_x','t_y','t_z']].values.reshape(60,order='F'),label_id)\n",
    "        data.append(np_data)\n",
    "    data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db863e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(26, 64):\n",
    "    for i in range(len(label)):\n",
    "        new_path = './combined_data/%s/0%g.csv'%(label[i],num)\n",
    "        try:\n",
    "            new_df = combine_t_w(num, label[i],i)\n",
    "            window_length = 10\n",
    "            stride = 1\n",
    "            if num == 26 and i == 0:\n",
    "                data_window = sliding_window(window_length, stride, new_df)\n",
    "            else:\n",
    "                temp_window = sliding_window(window_length, stride, new_df)\n",
    "                data_window = np.append(data_window, temp_window,axis=0)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59d50155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the embedding for each x,y,z\n",
    "class linear_embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_embedding, self).__init__()\n",
    "        self.layer1 = nn.Linear(10,16)\n",
    "        self.layer2 = nn.Linear(16,5)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "    def forward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "677fa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(deep_model, self).__init__()\n",
    "        self.le_w_x = linear_embedding()\n",
    "        self.le_w_y = linear_embedding()\n",
    "        self.le_w_z = linear_embedding()\n",
    "        self.le_t_x = linear_embedding()\n",
    "        self.le_t_y = linear_embedding()\n",
    "        self.le_t_z = linear_embedding()\n",
    "        self.layer1 = nn.Linear(30,16)\n",
    "        self.layer2 = nn.Linear(16,6)\n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "    def forward(self,x):\n",
    "        w_x = self.le_w_x(x[:,0:10])\n",
    "        w_y = self.le_w_y(x[:,10:20])\n",
    "        w_z = self.le_w_z(x[:,20:30])\n",
    "        t_x = self.le_t_x(x[:,30:40])\n",
    "        t_y = self.le_t_y(x[:,40:50])\n",
    "        t_z = self.le_t_z(x[:,50:60])\n",
    "        embedding = torch.cat((w_x,w_y,w_z,t_x,t_y,t_z),dim = 1)\n",
    "        x = self.layer1(embedding)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "813a15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_window)\n",
    "X = torch.Tensor(data_window[:,0:60])\n",
    "Y = torch.Tensor(data_window[:, 60].astype(int)).type(torch.long)\n",
    "test_count = 2000\n",
    "X_test = X[0:test_count]\n",
    "Y_test = Y[0:test_count]\n",
    "X_train = X[test_count:]\n",
    "Y_train = Y[test_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08657a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, Y_train),batch_size = 16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, Y_test),batch_size = 16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1999f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = deep_model()\n",
    "optimizer = torch.optim.Adam(my_model.parameters(),lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=20000,gamma=0.5)\n",
    "my_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38050e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 done, testing accuracy is 96.150000\n",
      "Epoch 1 done, testing accuracy is 100.000000\n",
      "Epoch 2 done, testing accuracy is 99.400000\n",
      "Epoch 3 done, testing accuracy is 100.000000\n",
      "Epoch 4 done, testing accuracy is 100.000000\n",
      "Epoch 5 done, testing accuracy is 100.000000\n",
      "Epoch 6 done, testing accuracy is 100.000000\n",
      "Epoch 7 done, testing accuracy is 100.000000\n",
      "Epoch 8 done, testing accuracy is 100.000000\n",
      "Epoch 9 done, testing accuracy is 100.000000\n",
      "Epoch 10 done, testing accuracy is 100.000000\n",
      "Epoch 11 done, testing accuracy is 100.000000\n",
      "Epoch 12 done, testing accuracy is 100.000000\n",
      "Epoch 13 done, testing accuracy is 100.000000\n",
      "Epoch 14 done, testing accuracy is 100.000000\n",
      "Epoch 15 done, testing accuracy is 100.000000\n",
      "Epoch 16 done, testing accuracy is 95.750000\n",
      "Epoch 17 done, testing accuracy is 99.500000\n",
      "Epoch 18 done, testing accuracy is 100.000000\n",
      "Epoch 19 done, testing accuracy is 100.000000\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "loss = 0\n",
    "for epoch in range(20):\n",
    "    my_model.train()\n",
    "    for x,y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = my_model(x)\n",
    "        loss = my_loss(output,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"%s: epoch %g current training loss is %f\"%(datetime.now(), epoch, loss))\n",
    "    scheduler.step()\n",
    "    my_model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            output = my_model(x)\n",
    "            _,predicted = torch.max(output.data,1)\n",
    "            correct += (predicted==y).sum().item()\n",
    "        print('Epoch %g done, testing accuracy is %f'%(epoch,correct/test_count*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6aea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
